# 152. Maximum Product Subarray

> Given an integer array `nums`, find a that has the largest product, and return the product. The test cases are generated so that the answer will fit in a 32-bit integer. 
> 
> Note that the product of an array with a single element is the value of that element.
> 
> **Constraints:**
> - `1 <= nums.length <= 2 * 104`
> - `-10 <= nums[i] <= 10`
> - The product of any subarray of `nums` is **guaranteed** to fit in a **32-bit** integer.

This problem is unique and therefore tricky: unlike most dynamic programming questions, the Bellman Equation is not a scalar field $\mathbb{Z}^n \to \mathbb{Z}$, but a vector field $\mathbb{Z} \to \mathbb{Z}^2$!

--- 

To begin, think about just two values $x, y$ and their product $xy$. Assume that $y$ is constant and $x$ is a variable.
1.  If $x < 0$, then $y < 0$ gives the largest value for $xy$. Moreover, we want to *minimise* $x$.
2.  If $x > 0$, then $y > 0$ gives the largest value for $xy$. Moreover, we want to *maximise* $x$.
3.  If $x = 0$, then $xy = 0$ regardless. 
How do we use this to solve the problem? Our Bellman equation must follow this, and therefore it must track *both the minimum and the maximum of the subarrays*!

Let $OPT(j) = (OPT_M(j), OPT_m(j)) \in \mathbb{R} \to \mathbb{R}^2$ be the maximum and minimum products in the subarray $A[0, j]$. As usual for DP questions, we compare $(OPT_M(j - 1), OPT_m(j - 1))$ and $A[j]$, as well as the products between them. Looking at just $OPT_M(j - 1)$ for now:
- If $A[j] > 0$ and $OPT_M(j - 1) > 0$, then the largest value we can get in is $OPT_M(j - 1)A[j]$.
- If $A[j] < 0$ and $OPT_m(j - 1) < 0$, then the largest value we can get in is $OPT_m(j - 1)A[j]$.
- If $A[j] > 0$ and $OPT_M(j - 1) \leq 0$, then the largest value (from a contiguous array) is $A[j]$. This occurs when there must be a break in contiguity of the array: since they are either opposite signed or there is a 0 in the calculation, it is better to start calculating starting from $A[j]$.
The same goes for calculating $OPT_m(i, j -1)$ but all the inequalities are flipped. To sum up,
$$
\begin{align*}
	OPT_M(j) &= \max(A[j], OPT_M(j - 1)A[j], OPT_m(j - 1)A[j]) \\
	OPT_m(j) &= \min(A[j], OPT_M(j - 1)A[j], OPT_m(j - 1)A[j]).
\end{align*}
$$
Note that the Bellman equation calculates subarrays *that end at a specific index*, and thus we can't simply return $OPT_M(n)$! In fact, we are calculating
$$
\max_{0 \leq j \leq n} OPT_M(j).
$$
We can do a bottom-up approach to calculate that.
```python
def maxProduct(self, nums: List[int]) -> int:
	# matrix storing all min and max of the product subarrays ending at index i
	opts = [[nums[0], nums[0]]]
	
	for i in range(1, len(nums)):
		curr_min = opts[i - 1][0]
		curr_max = opts[i - 1][1]
		
		# Bellman equation
		curr_opt = [
			min(nums[i], nums[i] * curr_min, nums[i] * curr_max),
			max(nums[i], nums[i] * curr_min, nums[i] * curr_max)
		]
		
		# update the matrix
		opts.append(curr_opt)
	
	return max(opt[1] for opt in opts)
```
We can simplify this further.
- Notice that we only use `opts[i]` once, to calculate `opts[i + 1]`. Thus, we can just use two variables `curr_min, curr_max` to do the calculations instead. Notice that they call each other in their calculations, so variable assignment must take place concurrently or temporary values must be used.
- Similarly, we are calculating the maximum subarray $A[0, j]$ at each iteration, and then finding the maximum by iterating through our list a second time. We can simply store the largest seen at each iteration to get the maximum.
```python
def maxProduct(self, nums: List[int]) -> int:
	largest = float('-inf')
	curr_min, curr_max = nums[0], nums[0]
	
	for i in range(1, len(nums)):
		curr_min, curr_max = (
			min(nums[i], nums[i] * curr_min, nums[i] * curr_max),
			max(nums[i], nums[i] * curr_min, nums[i] * curr_max)
		)
		
		largest = max(curr_max, largest)
	
	return largest
```
# Time Complexity
There is a for loop with constant time operation per iteration: the `min` and `max` comparisons are all fixed length, and the other operations are simply variable assignments or multiplication. This loops for $\mathcal{O}(n)$ iterations. The rest are constant time operations, so the algorithm runs in $\mathcal{O}(n)$ time.
# Space Complexity
There are only 3 variables used to calculate the product, so the algorithm has $\mathcal{O}(1)$ space complexity.
# Top-down Approach
A top-down approach starts by calculating the same $OPT(j) = (OPT_m(j), OPT_M(j))$. 
```python
def maxProduct(self, nums: List[int]) -> int:
	def maxSubProduct(j: int) -> (int, int):
		if j == 0:
			return nums[0], nums[0]
			
		prev_min, prev_max = maxSubProduct(j - 1)
		
		curr_min, curr_max = (
			min(nums[i], nums[i] * prev_min, nums[i] * prev_max),
			max(nums[i], nums[i] * prev_min, nums[i] * prev_max)
		)
		
		return curr_min, curr_max
	
	# ...
```
This is where memoisation comes in. We only want to calculate `maxSubProduct(i)` once for each `i`, but `maxSubProduct(i)` calls `maxSubProduct(i-1)` every time. Therefore we memoise the calculated value to ensure there is no duplicate calculation.
```python
def maxProduct(self, nums: List[int]) -> int:
	memo = {0: (nums[0], nums[0])}
	
	def maxSubProduct(i: int) -> (int, int):
		if i in memo:
			return memo[i]
			
		prev_min, prev_max = maxSubProduct(i - 1)
		
		curr_min, curr_max = (
			min(nums[i], nums[i] * prev_min, nums[i] * prev_max),
			max(nums[i], nums[i] * prev_min, nums[i] * prev_max)
		)
		
		memo[i] = (curr_min, curr_max)
		return curr_min, curr_max
	
	largest = float('-inf')
	for i in range(0, len(nums)):
		largest = max(largest, maxSubProduct(i)[1])
	
	return largest
```